# Методы МО
# Содержание
## Математические аспекты анализа данных и машинного обучения
**Лекции**
1. Введение в машинное обучение
   - https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing
1. Теория вероятностей и математическая статистика
   - https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf
   - https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf
   - https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf
   - Примеры распределений и их вид в зависимости от параметров: https://seeing-theory.brown.edu/probability-distributions/index.html#section3
   - Среднее значение (average) и дисперсия (variance), интерактивный пример: https://seeing-theory.brown.edu/basic-probability/index.html#section3
1. Линейная регрессия. Метод наименьших квадратов. Статистический вывод
   - https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf
   - [Математические модели и вычислительные методы обработки экспериментальных данных](https://raw.githubusercontent.com/ivtipm/ML/main/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf) раздел 2.4
3. Градиентный спуск и стохастический градиентный спуск
   - https://docs.google.com/presentation/d/1xPlGAycFwATMQaAjZnmdA1EffoS9gvamteUVaLcRsKA/edit?usp=sharing
5. Логистическая регрессия
6. Регуляризация линейной регрессии и логистической регрессии
7. Повторные выборки. Кросс-валидация. Выбор модели
8. Выбор признаков (отбор признаков на основе статистической значимости, создание новых признаков, ... )

### Практики
#### 1. Обзор основных средств анализа данных. Установка и настройка рабочей среды.
   - Python. pip. virtual enviroment? conda?
   - GNU Tools. cd, ls, pwd, ..., wc, cat, head, tail, less, diff?
   - Jupyter Notebook. Google Colaboratory. Kaggle.

#### Домашнее задание 1
   - Изучите возможности google collaboratore, ноутбуков kaggle.com, установите DataSpell
   - Посмотрите основные возможности библиотек NumPy и Pandas.  [ [Математические модели и вычислительные методы обработки экспериментальных данных](https://raw.githubusercontent.com/ivtipm/ML/main/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)  ] 
3. Библиотеки анализа данных и машинного обучения. 
   -  Numpy. Pandas. SciPy. Matplotlib. Seaborn. plotly. Sklearn.
#### Домашнее задание 2
Предвариательный ализ данных и визуализация:
- данные:https://www.kaggle.com/competitions/california-house-prices/overview
   - После согласования с преподавателем можно использовать свои данные
0. Зарегистрируйтесь на Kaggle
1. Изучите пропуски, дубликаты, числовые характеристики
2. Постройте графики:
      - пропусков
      - распределений, 
      - диаграммы размаха для отдельных величин, диаграммы размаха для одной величины в зависимости от значения категориальной величины,
      - попарные диаграммы размаха
2. Закодируйте нечисловые признаки
2. Напишите несколько простых и составных запросов для DataFrame, используйте группировки
3. Проверьте гипотезу о нормальности распределения
4. Комментируйте код
5. Сдайте работу в виде ссылки на тетрадку (Notebook) Google Colaboratory или Kaggle

Источники: 
1. [ [Математические модели и вычислительные методы обработки экспериментальных данных](https://raw.githubusercontent.com/ivtipm/ML/main/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)  ] 
2. https://colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR
3. Документация Pandas, Numpy, matplotlib, seaborn, scipy

   


5. Теория вероятностей и математическая статистика. Основные понятия. Корреляция. Законы распределения
6. Оптимизация. Метод наименьших квадратов, градиентный спуск, стохастический градиентный спуск.
7. Теория вероятностей и математическая статистика. Доверительный интервал. Проверка гипотез.
8. Линейная регрессия
9. Логистическая регрессия, многоклассовой классификации
10. Регуляризация и выбор модели. Отбор признаков.

#### Методы машинного обучения
**Лекции**
1. Метод опорных векторов и метод k-ближайших соседей
1. Байесовская линейная регрессия и наивный байесовский классификатор
1. Деревья решений и ансамбли методов
1. Кластеризация
1. Уменьшение размерности и метод главных компонент
1. Рекомендательные системы
1. Распределенные алгоритмы
1. Нейронные сети
1. Представление данных

**Практики**
1. Метрики качества классификатора. Классификация с несбалансированной выборкой.
3. Метод опорных векторов и k-ближайших соседей
4. Деревья решений
5. Комбинации моделей
6. Кластеризация. Метрики качества. Определение количества кластеров
7. Метод главных компонент PCA
8. Работа с категориальными признаками. Классификация текстовых документов
9. Рекомендательные системы
10. Модели представления данных

