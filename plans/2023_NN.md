# Нейросетевые технологии анализа данных

# Занятие 7. Transfer Learning, защита работ
- Повторение.
   - Переобучение. Отслеживание метрик на валидационной выборке во время обучения.
   - Отслеживание переобучения по графикам на wandb.
   - VGG, ResNet, Inception
- [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)
- Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing



# Занятие 6. Архитектуры CNN для классификации (продолжение)
1. Повторение. Распределение. Признаковое пространство. 
2. VGG, проблема затухающего градиента, ResNet (Skip Connection)
3. Использование предварительно обученных сетей.
   - Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing
   - [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)

### Домашнее задание 3. Классификация изображений.
Решите задачу классификации изображений на датасете Animal Faces-HQ (AFHQ), consists of 16,130 high-quality images at 512×512 resolution.

Источник данных: https://www.kaggle.com/andrewmvd/animal-faces
(Для загрузки необходима регистрация на kaggle, в верхней части страницы кнопка download для загрузки архива. Альтернативно: загрузка через kaggle api напрямую в colab: https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb )

Или ищите прямую ссылку на архив с данными в дискорде.



# Занятие 5. Архитектуры CNN для классификации
27 сентября
1. Повторение. Функции потерь. Функции активации. Архитектура свёрточной сети для классификации. Построение сестей в Pytorch
1. Инициализация весов: https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit?usp=sharing
2. VGG, проблема затухающего градиента, ResNet (Skip Connection)
- [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)

## Задание 2. CNN на основе примера. (продолжение)
https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=ePxpxkivl4Uy&line=26&uniqifier=1

*Бонус: Создайте веб-приложение в качестве интерфейса для модели обученной распозновать числа.*
Дополнительный балл за создание образа docker.

Пример создания интерфейса на основе Gradio: https://colab.research.google.com/drive/1SzAlYDLpjf65nnRbTVRtFxUWuyJnA8_s?usp=sharing#scrollTo=yGX_NM3aoN7V

### Задание 3. Классификация изображений

 
# Занятие 4. CNN
22 сертября, 18:30
- Повторение.
    - Построение нейросети Keras и Pytorch. Обучение.
    - SoftMax. Свёрточный нейрон и его гиперпараметры.
    - О роли функции активации в многослойном персептроне
- AlexNet, VGG, проблема затухающего градиента, ResNet (Skip Connection)
- Использование предварительно обученных сетей.
- Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing
- [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)

# Занятие 3. Повторение. Модификации градиентного спуска.
сентябрь 13
1. Повторение. Регрессия. Регуляризация. Логистическая регрессия. Обучение и переобучение. Линейная разделимость. Численный метод вычисления производной.
2. Модификации градиентного спуска. https://raw.githubusercontent.com/ivtipm/ML/main/Gradient%20Descent.pdf 
3. CNN. Архитектура нейросети для классификации изображений. Примеры PyTorch, Keras. [пример](https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing) 


## Задание 1. Продолжение: модификации градиентного спуска
1. Для программы на Питоне, минимизирующей выбранную функцию релизуйте модификации градиетного спуска:
    - ГД с моментом
    - ГД с моментом Нестерова



# Занятие 2. Повторение. Граф вычислений.
сентябрь 06

1. Повторение.
    - Граф вычислений. [слайды](https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit?usp=sharing), 
    - Вычисление производной сложной функции.
    - Метод обратного распространения ошибки.
    - Полносвязная нейросеть. Устройство. Построение выходного слоя в зависимости от задачи (классификация и кластеризация). Функции активации и функция потерь. 
    - Алгоритм обучения нейросети. [пример](https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing)
2. CNN. Архитектура нейросети для классификации изображений. Примеры PyTorch, Keras. [пример](https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing) 


## Задание 1. Минимизация функции методом градиентного спуска. Продолжение
1. Создайте программу на Питоне для минимизации выбранной функции. Задайте условие остановки на основе изменения функции.
2. Постройте график функции, отметьте на нём шаги метода.
    - Интерактивные графики, уменьшение размерности, веб-формы (plotly, PCA, gradio): colab.research.google.com/drive/1SzAlYDLpjf65nnRbTVRtFxUWuyJnA8_s     

## Задание 2. CNN на основе примера.
- Модифицируйте 2 нейросети из [примера](https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb?usp=sharing) так чтобы улучшить качество классификации.
- Полный текст задания: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=ePxpxkivl4Uy&line=25&uniqifier=1
- Ответьте на вопросы


# Занятие 1. Повторение. Начало CNN
сентябрь 02

1. Повторение. [слайды](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing)
   - Задачи МО. Классификация методов МО.
   - Метрики качества.
   - Обучение. Функция ошибок. Метод градиентного спуска. [pdf](https://github.com/ivtipm/ML/blob/main/Gradient%20Descent.pdf)
   - Полносвязные нейросети. [слайды](https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit?usp=sharing), [пример](https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing)
2. CNN. Основные идеи. [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)


## Задание 1. Минимизация функции методом градиентного спуска.
1. Выберете функцию одной переменной, по сложности сопоставимую с $L(x) = 3 x ^ 2 - sin(x) + e^x - 5$
2. Изобразите график функции
3. Сделайте 3 или больше шага метода градиентного спуска. Изобразите их на графике.
Можно записывать вычисления в LaTeX в Jupyter Notebook [ шпаргалка: [1](https://forketyfork.medium.com/latex-math-formulas-a-cheat-sheet-21e5eca70aae), [ 2 ](https://nbviewer.org/github/dingran/latex-ipynb/blob/master/latex-cheatsheet.ipynb) ]
