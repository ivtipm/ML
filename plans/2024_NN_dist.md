# Нейросетевые технологии анализа данных

## Результат успешного освоения курса
- Будете знать основы нейронных сетей, включая CNN, RNN, LSTM нейроны.
- На практике познакомитесь с построением нейросетей для классификации изображений, аугментации данных.
- Научитесь использоваться подход transfer learning для решения задач машинного зрения на примере задач классификации, детекции, сегментации;
- Познакомитесь с подходами к построению систем распознавания лиц
- Научитесь решить задачи анализа временных рядов классическими методами (SARAMAX и др. модели)
- Сможете использовать предобученные модели (такие как GPT и BERT) для решения задач анализа текста.
- Научитесь использовать LLM, в частности открытые, с локальным развёртыванием, для решения практических задач и изучения принципов работы с ними, включая создание эффективных промптов.




# Темы для самостоятельного изучения
- Модификации градиентного спуска. Инициализации весов.
- Аппаратное обеспечение для запуска и обучения нейросетевых моделей.
    - Современные модели процессоров для массовой параллельной обработки данных. o
    - Настройка среды: CUDA, фреимворки для запуска и обучения моделей.
    - Использование моделей на маломощных устройствах (смартфоны, носимая электроника, IoT и т.п.)
    - Распределённые вычисления?
- Neural Architecture Search (NAS) - современные методы автоматического поиска архитектур нейросетей
- Методы самообучающихся агентов (AutoML) -автоматизация процессов создания, тренировки и оценки моделей, в том числе выбор гиперпараметров, оптимизация модели.
- Методы интерпретируемости нейросетей
- Обучение представлений (Representation Learning)
- Графовая нейронная сеть (англ. Graph Neural Network, GNN)
- Federated Learning - распределённое обучение на данных, которые остаются локально на устройствах
- Современные архитектуры LLM. Квантизация. Адаптеры (LORA).
- Разработка и тестирование систем на основе RLHF (Reinforcement Learning with Human Feedback)
- RAG системы
- ИИ-агенты на основе LLM
- Mixture of experts (MoE)
- Обучение с подкреплением (Reinforcement Learning, RL).
- Generative Adversarial Networks (GANs) — модели, которые состоят из двух нейросетей: генератора и дискриминатор.
- Диффузионные модели.
- Обработка звука, сигналов. Модель speech-to-text [whisper](https://github.com/openai/whisper?tab=readme-ov-file)
- Этика и ответственность в ИИ

См. также [план](2023_NN.md) для студентов очного обучения.


# Заочное 2024.
# Занятие 1. Повторение. Персептрон. CNN
8 ноября
1. Повторение
    - Шпаргалка по Python https://miro.com/app/board/uXjVNQC1rq8=/?share_link_id=860218532001
    - Теория вероятностей и математическая статистика
        - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf)
        - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf)
        - [raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf)
        - Примеры распределений и их вид в зависимости от параметров: [seeing-theory.brown.edu/probability-distributions/index.html#section3](https://seeing-theory.brown.edu/probability-distributions/index.html#section3)
        - Среднее значение (average) и дисперсия (variance), интерактивный пример: [seeing-theory.brown.edu/basic-probability/index.html#section3](https://seeing-theory.brown.edu/basic-probability/index.html#section3)
    - Введение в МО
        - Введение: [docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing)

        - [EDA, предобработка, кодирование colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR](https://colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR)    

1. Полносвязные нейросети. [слайды](https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit?usp=sharing), [пример](https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing)

2. CNN. Основные идеи. [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80)
    - Представление изображений в виде тензора
    - Операция свёртки, свёртка для одноканального и трёхканальгого изображения, гиперпараметры операции
    - Пулинг
    - Архитектура нейросети для получения векторных представлений изображений
    - AlexNet, VGG, проблема затухающего градиента, ResNet (Skip Connection), Inception
    - Использование предварительно обученных сетей (transfer Learning).
    - Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb



# Задание 1. Классификация с помощью многослойного персептрона
0. Приведите ссылку на задание, текст задания.
1. Сгенерируйте данные. Создайте 5 или больше независимых признака, в том числе 1-2 лишних, 2 класса. [ [пример](https://colab.research.google.com/drive/1AdbtsRkX0jRVByuAKJxchYPcciTgFpqh#scrollTo=57PKhQ2Ylni1) ]. Создавайте не более 10 тысяч объектов.
1. Исследуйте данные. 
    - Изучите числовые характеристики всех признаков через 7-point summary. Используйте метод `describe()` класса pandas.DataFrame. Напишите пояснения для этих характеристик.
    - Постройте диаграммы размаха для всех признаков (seaborn.boxplot), скрипичные диаграммы (violinplot). Напишите пояснения. Есть ли выбросы?
    - Разберитесь как задать размер полотна (изображения) для графиков? Как построить несколько графиков, на одном полотне, но с разными осями? Постройте несколько диаграмм размаха 
    - Постройте гистограмму для целевого признака. Используйте рекомендованное библиотекой число столбцов, задайте много столбцов. Опишите, как такая гистограмма устроена. Видны ли на гистограмме с большим количеством столбцов аномалии в данных?
    - Вычислите матрицу корреляции, сделайте для неё тепловую карту. Напишите, какие независимые признаки влияют на целевой сильнее всего? Есть ли математическая зависимость между независимыми признаками? Как это влияет на качество уравнения логистической регрессии? Имеет ли смысл считать коэф. корреляции для категориального признака?
    - Постройте попарные дигаммы рассеяния (seabor.pairplot). Кодируйте класс цветом. Что показывает такая диаграмма? Постройте для этого признака отдельную диаграмму рассеяния (seaborn.jointplot).
    - Дополнительно используйте пакет plotly для построения двухмерной и трёхмерной диаграммы рассеяния. На диаграмме должен быть целевой признак, и два наиболее значимых независимых признака.
    - Бонус: дополнительно постройте диаграммы на свой выбор. 
1. Обучите модель логистической регрессии. Приведите общую формулу, пояснения для неё. Приведите функцию потерь, пояснения к ней. Зачем она нужна?
1. Обучите многослойный (2+ слоя) персептрон.
    - Опишите его структуру: слои, количество нейронов на слоях, количество входов на каждом слое, функцию активации; общее количество параметров нейросети.
1. Оцените модели на отложенной выборке. Вычислите accuracy (общую точность), точность (precision), recall (полноту), меру f1. Опишите эти показатели. 
3. Напишите пояснения и комментарии к коду. Поясняйте общий алгоритм, смысл действий, понятия (std, mean, ...) параметры вызываемых функций, записанные в коде формулы (приведите их в LaTeX). Комментарии к коду можно оставлять в ячейках с кодом, остальные пояснения можно давать в ячейках с текстом.


## Задание 2. CNN на основе примера классификации рукописных цифр
Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=ePxpxkivl4Uy&line=26&uniqifier=1
1. Исследуйте данные.
1. Подберите гиперпараметры модели на Keras (*дополнительно:  PyTorch*)
    * Гиперпараметры обучения: количество эпох, шаг обучения, количество и конфигурация слоёв. Не забывайте про нормализацию и dropout.
    - Объясните, почему выбрали именно такую архитектуру. Прокомментируйте все слои, их гиперпараметры. Задайте важные гиперпараметры в явном виде вместо неявного использования значения по умолчанию.
    - Какую функцию потерь использовали? Почему?
    - Сколько параметров получилось? На каких слоях больше всего обучаемых параметров?
    - Как максимизировали качество модели? Как минимизировали размер модели?
    - Как контролировали переобучение? Как боролись с ним?
    - Как можно ускорить обучение?
1. Используйте готовые модели из библиотек Keras (*дополнительно: Pytorch*)
    - Что такое transfer learning?
    - Какие варианты использования (обучения) этих моделей существуют?
    - Почему здесь предварительно обученная на другом датасете нейросеть (кроме последних слоёв) может работать на данном датасете?
1. *Используйте аугментацию изображений (для всех моделей). Не изменяйте изображения слишком сильно.*
    - Зачем нужна аугментация? Как она работает?
    - Как влияет на время обучения? На обобщающую способность модели?
    - Какие характеристики изображения можно изменять? Как они влияют на качество модели и время обучения?
1. *Отслеживайте обучение через сервис WandB. Можно использовать локальные инструменты для отслеживания вместо WandB*
    - Записывайте гиперпараметры модели, количество параметров модели, гиперпараметры обучения.
    - Стройте графики во время обучения (для обучающей и валидационной выборок).
    - Записывайте качество модели на тестовой выборке.
    - Постройте график в параллельных координатах, по которому можно оценить влияние гиперпараметров на качество предсказания.
1. Измерьте качество моделей на тестовой выборке.
1. Структурирование работы, комментарии и справка. Дополните код поясняющими комментариями.
    - Описывайте общий алгоритм работы с данными и моделями.
    - Поясняйте используемые классы, функции и их параметры.
    - Приводите ссылки на документацию, справочные материалы, поясняющие изображения и т.п.
    - Запишите ответы на вопросы в python-тетрадке
    - *Дополнительный балл за создание схемы нейросети (потока данных через нейросеть)*
1. Выводы.
    - Опишите эксперименты. Описывайте не только результаты, но и объясняйте их влияние на качество и размер модели. Описывайте как влияют гиперпараметры на точность, время обучения и т.п.
    - Пишите в выводах как ещё можно [попробовать] улучшить качество модели или оптимизировать её размер.
1. Используйте предварительно сохранённую нейросеть для классификации.
1. *Дополнительный балл за веб-приложение в качестве интерфейса для модели обученной распознавать числа.*
1. *Дополнительный балл за создание образа docker*:
    - балл за сервер, отвечающий на запросы по API
    - балл за сервер, отвечающий за сервер, на котором доступен веб-интерфейс* [[пример](../examples/docker-ML-web)]
    - балл за систему из API сервера и веб-сервера [[пример](../examples/docker-api/)]
1. *Дополнительный балл за использование похожего, но более сложного датасета.*
git
Пример создания интерфейса на основе Gradio: https://colab.research.google.com/drive/1SzAlYDLpjf65nnRbTVRtFxUWuyJnA8_s?usp=sharing#scrollTo=yGX_NM3aoN7V

Курсивом выделены необязательные пункты.


# Занятие 2.
- RNN. Принцип работы. Обучение. Несколько RNN нейронов.
- Эмбеддинги слов. Готовый словарь и создание собственного.
- Архитектура сети для классификации текстов по тональности.
- Пример Keras. pytorch.
- Слайды: https://docs.google.com/presentation/d/1cU08j3zl3rpBa00hjsP5Hrz8H-9-WR5Y4Z22K_N7mQU/edit?usp=sharing
- Примеры:
- https://colab.research.google.com/drive/1XXQgLdECny8MvO8VVcEn3-cM1TW8pdHK — основы RNN
- https://colab.research.google.com/drive/1-DR0TUO-2WPT9xp8LaC6OOJxKbnbG6NO — применение RNN для классификации текстов

- Трансформеры
    - BPE
    - Self-Attention
    - Transformers. GPT
    - Слайды: https://docs.google.com/presentation/d/1Kpk3DcHNf1iOMcggF701VorNuI3csqcuU9G69mUxtZU/edit?usp=sharing

    - Пример классификации текстов моделью GPT2 (distilgpt2, huggin face transformers, pytorch)
https://drive.google.com/file/d/1euX-lo9QgNEpNats9Pkl1YVvY7IdQTnk
    - Пример использования BERT для создания векторных представлений текстов: https://colab.research.google.com/drive/1Aacg8tUXXNICQ0SetvqoIPD7GXnm0Ymx?usp=sharing


# Задание 3. Классификация текстов.

1. Решите задачу классификации текстов. https://github.com/ivtipm/ML/blob/main/ML/text_classification.md (см. также задание из курса по методам машинного обучения).

1. Используйте произвольную не нейросетевую модель: дерево решений, случайный лес, градиентный бустинг
1. Используйте RNN сеть (LSTM или GRU) и слой для создания эмбеддингов
1. Используйте кодировщик трансформера (нейросеть на основе BERT) для создания векторного представления текста, далее классифицируйте векторные представления текстов.
1. Оцените качество моделей на тестовой выборке.

1. Структурирование работы, комментарии и справка. Дополните код поясняющими комментариями.
    - Описывайте общий алгоритм работы с данными и моделями.
    - Поясняйте используемые классы, функции и их параметры.
    - Приводите ссылки на документацию, справочные материалы, поясняющие изображения и т.п.
    - Запишите ответы на вопросы в python-тетрадке
    - *Дополнительный балл за создание схемы нейросети (потока данных через нейросеть)*
1. Выводы.
    - Опишите эксперименты. Описывайте не только результаты, но и объясняйте их влияние на качество и размер модели. Описывайте как влияют гиперпараметры на точность, время обучения и т.п.
    - Пишите в выводах как ещё можно [попробовать] улучшить качество модели или оптимизировать её размер.
3. *Бонус: создайте веб-приложение*
4. *Бонус: создайте образ docker*

Можно предлогать свой датасеты аналогичные по объёму и сложности.


# Экзамен
Допуск на экзамен - выполнены минимум две работы.

Удовлетворительно:
- Выполнены две работы.
- Собеседование по темам двух выполненных работ.

Хорошо или Отлично
- Выполнены три работы
- Собеседование по темам трёх выполненных работ.







