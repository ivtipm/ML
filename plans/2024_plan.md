# О курсе
Курс посвящён машинному обучению, направлению искусственного интеллекта, где задачи решаются на основе анализа данных. Нередко большого количества данных. В курсе будут рассмотрены основные понятия машинного обучения, способы анализа и визуализации данных, преобразования данных в вид, подходящий для моделей машинного обучения. Будут рассмотрены классические модели машинного обучения, начиная от регрессий, заканчивая градиентным бустингом; методы обучения и оптимизации качества этих моделей. В конце курса будут рассмотренные полносвязные нейросети (многослойные персепторн). 

Задания будут посвящены преимущественно обработке табличных и текстовых данных на примере синтетических и реальных наборов данных.

Рассматриваемые не нейросетевые методы МО применяются на практике, не смотря на большую популярность нейросетей. Курс можно считать как самостоятельным, так и длинным, но во многом обязательным, введением в курс нейросетевого анализа данных. Последний будет проходить в следующем семестре.

**См. также** план предыдущего курса, ссылки и примеры на главной странице, записи лекций предыдущего курса в дискорде.

## Требования для успешного усвоения курса.

Для успешного освоения курса необходимы знания языка программирования Python, основ линейной алгебры, математического анализа и методов оптимизации.

### Материалы для ознакомления перед началом курса
0. Шпаргалка по Python https://miro.com/app/board/uXjVNQC1rq8=/?share_link_id=860218532001
0. Теория вероятностей и математическая статистика
    - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf)
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf)
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf)
   - Примеры распределений и их вид в зависимости от параметров: [seeing-theory.brown.edu/probability-distributions/index.html#section3](https://seeing-theory.brown.edu/probability-distributions/index.html#section3)
   - Среднее значение (average) и дисперсия (variance), интерактивный пример: [seeing-theory.brown.edu/basic-probability/index.html#section3](https://seeing-theory.brown.edu/basic-probability/index.html#section3)

0. Математическая статистика, основы numpy, pandas, matplotlib
    1. [Математические модели и вычислительные методы обработки экспериментальных данных](https://raw.githubusercontent.com/ivtipm/ML/main/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)
    1. 6 способов значительно ускорить pandas с помощью пары строк кода: https://habr.com/ru/articles/503726/, https://habr.com/ru/articles/504006/


# План
# 1. Введение в машинное обучение. Математическая статистика. NumPy. Pandas.
1. Введение: [docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing)
1. Теория вероятностей и математическая статистика:
    - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf)
    - [raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf)

### Задание 1. NumPy и основные понятия математической статистики
Не используйте никакие методы numpy array кроме sum. Не используйте циклы, используйте векторные вычисления.

Используйте Google Colaboratory.

1. Для функций ошибок и величин, широко используемых в анализе данных и машинном обучении напишите функции:
    1. для вычисления стандартного отклонения случайной величины;
    1. для вычисления ошибок MSE, MAE, accuracy, precision, recall, f1 score. 
    Функции должны принимать два параметра y_pred, y_true. См. аналогичные функции из библиотеки sklearn;
    1. для вычисления функции softmax на нескольких переменных, используйте `numpy.exp`;
    1. вычисления линейного коэффициента корреляции;
    1. для вычисления предсказания для нескольких объектов по заданному коэффициентами уравнения линейной регрессии;
    1. подбора коэффициентов линейной регрессии, с использованием метода наименьших квадратов и функцией `minimize` модуля `scipy.optimize`.
1. Напишите тесты для этих функций;
1. Пишите поясняющие и документирующие комментарии;
1. Напишите формулы в формате LaTeX для всех функций, пояснения к формулам.

Для проверки кода, связанного с регрессией можно воспользоваться функцией `make_regression` из библиотеки Sklearn. Она создаёт синтетические данные для задачи регрессии. 

Задание может быть дополнено.



# 
2. [EDA, предобработка, кодирование colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR](https://colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR)

2. [Линейная регрессия. МНК. Метод макс.правдоподобия. sklearn.ipynb colab.research.google.com/drive/1YadlNYk9_WkCQY6L-HKP9SI7xZjuzIMx](https://colab.research.google.com/drive/1YadlNYk9_WkCQY6L-HKP9SI7xZjuzIMx?usp=sharing)