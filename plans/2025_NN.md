# Нейросетевые технологии анализа данных

## Результат успешного освоения курса
- Будете знать основы нейронных сетей, включая CNN, RNN, LSTM нейроны.
- На практике познакомитесь с построением нейросетей для классификации изображений, аугментации данных.
- Научитесь использоваться подход transfer learning для решения задач машинного зрения на примере задач классификации, детекции, сегментации;
- Познакомитесь с подходами к построению систем распознавания лиц
- Научитесь решить задачи анализа временных рядов классическими методами (SARAMAX и др. модели)
- Сможете использовать предобученные модели (такие как GPT и BERT) для решения задач анализа текста.
- Научитесь использовать LLM, в частности открытые, с локальным развёртыванием, для решения практических задач и изучения принципов работы с ними, включая создание эффективных промптов.




# Темы для самостоятельного изучения
- Модификации градиентного спуска. Инициализации весов.
- Аппаратное обеспечение для запуска и обучения нейросетевых моделей.
    - Современные модели процессоров для массовой параллельной обработки данных. o
    - Настройка среды: CUDA, фреимворки для запуска и обучения моделей.
    - Использование моделей на маломощных устройствах (смартфоны, носимая электроника, IoT и т.п.)
    - Распределённые вычисления?
- Neural Architecture Search (NAS) - современные методы автоматического поиска архитектур нейросетей
- Методы самообучающихся агентов (AutoML) -автоматизация процессов создания, тренировки и оценки моделей, в том числе выбор гиперпараметров, оптимизация модели.
- Методы интерпретируемости нейросетей
- Обучение представлений (Representation Learning)
- Графовая нейронная сеть (англ. Graph Neural Network, GNN)
- Federated Learning - распределённое обучение на данных, которые остаются локально на устройствах
- Современные архитектуры LLM. Квантизация. Адаптеры (LORA).
- Разработка и тестирование систем на основе RLHF (Reinforcement Learning with Human Feedback)
- RAG системы
- ИИ-агенты на основе LLM
- Mixture of experts (MoE)
- Обучение с подкреплением (Reinforcement Learning, RL).
- Generative Adversarial Networks (GANs) — модели, которые состоят из двух нейросетей: генератора и дискриминатор.
- Диффузионные модели.
- Обработка звука, сигналов. Модель speech-to-text [whisper](https://github.com/openai/whisper?tab=readme-ov-file)
- Этика и ответственность в ИИ

План прошлого года: https://github.com/ivtipm/ML/blob/main/plans/2024_NN.md

# Занятие 1. LLM. Prompt engineering.
1 сентября
- Обзор курса
- Пожелания по темам?
- Prompt Engineering
- Слайды: https://docs.google.com/presentation/d/1y_R99DlMprkxNmDjhekuONVODyO0CUCpOD2AmyMaZhs/edit?usp=sharing
- Сравнение сервисов с LLM: https://github.com/ivtipm/ML/blob/d40a2afc57ff0da4400be7ddd0a5ba41ddc6bf53/slides%20etc/%D0%A2%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0%20%D0%98%D0%98-%D0%B0%D1%81%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%BE%D0%B2.pdf

# Задание 1 - Написание промтов
https://github.com/ivtipm/ML/blob/main/tasks/task_LLM_use.md 



# Занятие 3-4. Введение в CNN

1. Повторение. [слайды](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing)
    - Задачи МО. Классификация методов МО.
    - Метрики качества.
    - Обучение. Функция ошибок. Метод градиентного спуска. [pdf](https://github.com/ivtipm/ML/blob/main/Gradient%20Descent.pdf)
    - Полносвязные нейросети. [слайды](https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit?usp=sharing), [пример](https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing)
2. CNN. Основные идеи. [слайды](https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing)
    - Представление изображений в виде тензора
    - Операция свёртки, свёртка для одноканального и трёхканальгого изображения, гиперпараметры операции
    - Пулинг
    - Архитектура нейросети для получения векторных представлений изображений


## Задание 2. CNN на основе примера классификации рукописных цифр
Пример: https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=ePxpxkivl4Uy&line=26&uniqifier=1
1. Исследуйте данные.
1. Подберите гиперпараметры моделей на PyTorch и Keras
    * Гиперпараметры обучения: количество эпох, шаг обучения, количество и конфигурация слоёв. Не забывайте про нормализацию и dropout.
    - Объясните, почему выбрали именно такую архитектуру. Прокомментируйте все слои, их гиперпараметры. Задайте важные гиперпараметры в явном виде вместо неявного использования значения по умолчанию.
    - Какую функцию потерь использовали? Почему?
    - Сколько параметров получилось? На каких слоях больше всего обучаемых параметров?
    - Как максимизировали качество модели? Как минимизировали размер модели?
    - Как контролировали переобучение? Как боролись с ним?
    - Как можно ускорить обучение?
1. Используйте готовые модели из библиотек Keras и Pytorch.
    - Что такое transfer learning?
    - Какие варианты использования (обучения) этих моделей существуют?
    - Почему здесь предварительно обученная на другом датасете нейросеть (кроме последних слоёв) может работать на данном датасете?
1. Используйте аугментацию изображений (для всех моделей). Не изменяйте изображения слишком сильно.
    - Зачем нужна аугментация? Как она работает?
    - Как влияет на время обучения? На обобщающую способность модели?
    - Какие характеристики изображения можно изменять? Как они влияют на качество модели и время обучения?
1. Отслеживайте обучение через сервис WandB. Можно использовать локальные инструменты для отслеживания вместо WandB
    - Записывайте гиперпараметры модели, количество параметров модели, гиперпараметры обучения.
    - Стройте графики во время обучения (для обучающей и валидационной выборок).
    - Записывайте качество модели на тестовой выборке.
    - Постройте график в параллельных координатах, по которому можно оценить влияние гиперпараметров на качество предсказания.
1. Структурирование работы, комментарии и справка. Дополните код поясняющими комментариями.
    - Описывайте общий алгоритм работы с данными и моделями.
    - Поясняйте используемые классы, функции и их параметры.
    - Приводите ссылки на документацию, справочные материалы, поясняющие изображения и т.п.
    - Запишите ответы на вопросы в python-тетрадке
    - *Дополнительный балл за создание схемы нейросети (потока данных через нейросеть)* [https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network]
1. Выводы.
    - Опишите эксперименты. Описывайте не только результаты, но и объясняйте их влияние на качество и размер модели. Описывайте как влияют гиперпараметры на точность, время обучения и т.п.
    - Пишите в выводах как ещё можно [попробовать] улучшить качество модели или оптимизировать её размер.
1. Используйте предварительно сохранённую нейросеть для классификации.
1. *Дополнительный балл за веб-приложение в качестве интерфейса для модели обученной распознавать числа.*
1. *Дополнительный балл за создание образа docker*:
    - балл за сервер, отвечающий на запросы по API
    - балл за сервер, отвечающий за сервер, на котором доступен веб-интерфейс* [[пример](../examples/docker-ML-web)]
    - балл за систему из API сервера и веб-сервера [[пример](../examples/docker-api/)]
1. *Дополнительный балл за использование похожего, но более сложного датасета.*
git
Пример создания интерфейса на основе Gradio: https://colab.research.google.com/drive/1SzAlYDLpjf65nnRbTVRtFxUWuyJnA8_s?usp=sharing#scrollTo=yGX_NM3aoN7V



# Занятие 5. ViT, Transfer Learning, Semi supervised Learning, CLIP ...
- Архитектура Vision Transformer (ViT). Коротко о модели Трансформер. Подача изображения в модель. Механизм внимания (attention).
- Transfer learning. Общие подходы.
- Self Supervised Learning (SSL).
- OneShot классификация с CLIP.

Слайды:
- ViT: https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit?usp=sharing
- TL, SSL, CLIP: https://docs.google.com/presentation/d/1SXKAczixGdgbHOCXGbYTAlKr2-Z6ctjuSMfjP8oqxKk/edit?usp=sharing

Пример использования CLIP: https://colab.research.google.com/drive/1IBdKzbY3sQBb7C2o03rZlLH_oYBVOpb1

# Занятие 6-7. Детекция, YOLO и др. модели на основе ViT. Сегментация, FCN, U-Net, SegNet
3-10 октября
- Задача детекции объектов на изображении.
    - Примеры задачи. Некоторые датасеты (COCO, Pascal VOC, ...)
    - Показатели качества: IoU, AP75, mAP;
    - Общие подходы к детекции (одностадийная и двухстадийная детекция), перечень важных и популярных архитектур.
    - Архитектура YOLO: общее устройство, принцип обнаружения объектов, выходной тензор, функция потерь, якоря для размеров объектов; Актуальные версии модели. Сравнение с другими моделями по точности и скорости.
    - Похожие архитектуры: SSD, RetinaNet
    - NonMaximum Suppression
    - Слайды: https://docs.google.com/presentation/d/105hLZaG1FQGqiL6Z_QDsk4rRm3gt0RSvm5EilzJ71R8/edit?usp=sharing
    - Пример (Детекция RetinaNet, сегментация): https://colab.research.google.com/drive/1qn4PrfSFq1NHdplxtMA1w6jehqYNLBgr?usp=sharing
    - Пример: YOLO: [../examples/yolo.ipynb](../examples/yolo.ipynb)
- Семантическая сегментация?

### Домашнее задание 3. Детекция
- Создайте веб-интерфейс для предварительно обученной модели детекции (YOLO, RetinaNet и т.п.)
- Пользователь может загрузить изображение,
- выбрать параметры детекции: набор классов, количество детектируемых объектов на каждый класс, минимальный уровень уверенности в детекции объекта
- Решите задачу классификации используя предварительно обученную модель CLIP
- *Бонус: создайте docker-образ*
    - *создайте один образ, который содержит модель и сервер, обрабатывающий ввод пользователя* [[пример](../examples/docker-ML-web)]
    - *или создайте два образа: один с сервером обрабатывающим запросы к модели [[пример](../examples/docker-api/)]; другой с сервером предоставляющим пользовательский интерфейс и соверщаюшим запросы к серверу с моделью*
- *Бонус: дообучите готовую модель решать задачу детекции для новых классов*
- *Бонус: детекция и распознавание номерных знаков или предложите решение своей задачи*


# Экзамен