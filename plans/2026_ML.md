# План
32 ч. лекции + 32 ч. практики

1. Обзор основных парадигм, задач, методов и моделей
2. Простейшие алгоритмы. kNN. Наивный Байес (Naive Bayes).
3. Поиск по сетке гиперпараметров.
3. Деревья решений
4. Метод опорных векторов (SVM). Понятие гиперплоскости и ядра (kernels).
5. Ансамблевые методы.Концепция ансамблей. Bagging. случайный лес (Random Forest). Boosting: адаптивный  и градиентный бустинг.  Stacking. Blending.
8. Кластеризация и понижение размерности. Обучение без учителя. k-средних (k-means) и DBSCAN. Понижение размерности: Principal Component Analysis (PCA).
9. Рекомендательные системы. Основные подходы: контентные, коллаборативные. Применение простейших алгоритмов (например, матричная факторизация).
10. Пайплайны и отслеживание экспериментов. Использование scikit-learn.pipeline для организации всего процесса. Инструменты для отслеживания экспериментов (MLflow, Weights & Biases).
11.Персептрон для табличных данных. Кривые обучения.


# Экзамен
