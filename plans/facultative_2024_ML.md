# ДПО. Модуль: машинное обучение

(+) помечены обязательные работы или обязательные пункты работы.

См. журнал с отметками в канале в телеграмме. 

# Занятие 1. Введение в МО.
3 февраля
1. Понятие МО. Задачи МО: классификация и регрессия.
2. Представление данных. Виды признаков по природе значений (числовой, номинальный, категориальный). \
Виды признаков по задаче (независимые, зависимые (целевые))
3. Пример проекта в среде Jupyter Notebook в сервисе Google Colaboratory: обучение модели линейной регрессии с помощью библиотеки SKLearn [[подробнее про линейную регрессию](https://colab.research.google.com/drive/1YadlNYk9_WkCQY6L-HKP9SI7xZjuzIMx?usp=sharing#scrollTo=pxeShTXsN2xZ)]

- Слайды: https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing
- Пример: https://colab.research.google.com/drive/18YGaumubomt-Rtg_9_VT_nf1GwbMlEx8?usp=sharing

См. запись занятия в чате группы


### Домашнее задание 0. Основы Google colab. Синтетические данные. Простое исследование данных. Линейная регрессия. (+)
1. Освойтесь в google colaboratory
    - Как создавать ячейки? Какие виды ячеек бывают?
    - Какие способы запуска ячеек есть? Как ячейки с кодом влияют друг на друга?
    - Что такое markdown? Как создавать заголовки (и просматривать их в Google Colaboratory), делать текст жирным, курсивом, приводить фрагменты кода с подсветкой синтаксиса, приводить формулы в записи LaTeX?
    - Как делиться проектом (тетрадкой - notebook)?
    - upd: приведите ссылку на задание, текст задания.
1. upd: Исследуйте данные. 
    - Изучите числовые характеристики всех признаков через 7-point summary. Используйте метод `describe()` класса pandas.DataFrame. Напишите пояснения для этих характеристик. (+)
    - Вычислите те же характеристики используя библиотеку numpy, используйте только методы sum, min, max, quantile.
    - Постройте диаграммы размаха для всех признаков (seaborn.boxplot)
    - Постройте гистограмму для целевого признака. Используйте рекомендованное библиотекой число столбцов, задайте много столбцов. Опишите, как такая гистограмма устроена. Видны ли на гистограмме с большим количеством столбцов аномалии в данных?
    - Вычислите матрицу корреляции, сделайте для неё тепловую карту. Напишите, какие независимые признаки влияют на целевой сильнее всего? Есть ли математическая зависимость между независимыми признаками? Как это влияет на качество уравнения линейной регрессии? (+)
    - Постройте попарные дигаммы рассеяния (seabor.pairplot). Что показывает такая диаграмма? Для какого распределения целевого признака предсказания уравнения линейной регрессии будут точнее всего? Постройте для этого признака отдельную диаграмму рассеяния (seaborn.jointplot)
    - См. примеры по ссылке из лекции и на доске: https://miro.com/app/board/uXjVNQC1rq8=/?moveToWidget=3458764569672021118&cot=14
1. Изучите пример. Попробуйте обучить модель (линейную регрессию) для другого числа объектов и признаков. Проверьте полученное уравнение. (+)
2. Разделите исходные данные на выборку для обучения (train) и отложенную выборку (test) для проверки результатов обучения. Оцените качество модели на этих выборках. Почему результаты могут отличаться? (+)
    - Вычисляйте ошибку MSE, MAE. Используйте встроенные в sklearn функции. (+)
    - Вычислите стандартное отклонение ошибки.
    - Реализуйте эти вычисления самостоятельно, используя массив NumPy, но не используйте никакие методы кроме суммы.
    - upd: вычислите коэффициент детерминации R2. О чём он говорит? (+)
3. Напишите пояснения и комментарии к коду. Поясняйте общий алгоритм, смысл действий, понятия (std, mean, ) параметры вызываемых функций, записанные в коде формулы (приведите их в LaTeX). Комментарии к коду можно оставлять в ячейках с кодом, остальные пояснения можно давать в ячейках с текстом.



# Занятие 2. Введение в МО. Линейная регрессия
1. Повторение. Опрос.
    - Что такое МО? Чем оно отличается от решения задач традиционным программированием?
    - Какие задачи может решать МО? На какие подвиды делиться задача прогнозирования (предсказания)? Чем они отличаются?
    - Как представляют данные в МО? Какие виды признаков бывают?
    - Какая модель МО была рассмотрена на прошлом занятии? Как её можно описать? Как её обучить?
    - Что такое Jupyter Notebook? Что такое Google Colaboratory? Как в тетрадке (notebook) сделать заголовки? Как поделиться? Как форматировать текст?
1. Показатели качества моделей [[Слайды](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit?usp=sharing)] регрессии. Коэффициент детерминации.

1. Основы математической статистики:
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_1.pdf)
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/variables_2.pdf)
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf)
   - Примеры распределений и их вид в зависимости от параметров: [seeing-theory.brown.edu/probability-distributions/index.html#section3](https://seeing-theory.brown.edu/probability-distributions/index.html#section3)
   - Среднее значение (average) и дисперсия (variance), интерактивный пример: [seeing-theory.brown.edu/basic-probability/index.html#section3](https://seeing-theory.brown.edu/basic-probability/index.html#section3)

1. NumPy. Pandas.
    - [Математические модели и вычислительные методы обработки экспериментальных данных](https://github.com/ivtipm/ML/blob/2c81049c9f1056d3be594642fde8c70d2d268d25/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)


- Пример: https://colab.research.google.com/drive/18YGaumubomt-Rtg_9_VT_nf1GwbMlEx8?usp=sharing


# Занятие 3. Введение в МО. Корреляция. Статистические визуализации
12 февраля

0. Повторение. Опрос. Объекты и признаки. Целевой признак, независимые признаки. Дисперсия, математическое ожидание, квартили. Тренировочная и тестовая выборка. Переобучение. Классификация и регрессия. Оценка качества регресии, MAE, MSE, R2.
1. Основы математической статистики:
   - [raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf](https://raw.githubusercontent.com/VetrovSV/AppMathST/master/statistics.pdf)
   - Выборки
   - Корреляция и уравнение регреcсии
   - Коэффициент детерминации R2 [[слайды](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit#slide=id.ga34d6fd6e8_0_572)]

# Занятие 4. Функция потерь для линейной и логиcтической регрессии.
0. Повторение. Модель машинного обучения. Виды признаков по их природе. Линейная регрессия.
1. Подбор параметров уравнения регрессии.
    - Аналитический
    - Численный
    - Масштабирование признаков
        - Нормирование
        - Стандартизация
    - [Теория, Пример](https://colab.research.google.com/drive/1YadlNYk9_WkCQY6L-HKP9SI7xZjuzIMx)
1. Вероятностная модель. Логистическая регрессия
    [Теория,Пример](https://colab.research.google.com/drive/1AdbtsRkX0jRVByuAKJxchYPcciTgFpqh)
1. Показатели качества модели классификации (accuracy (общая точность), точность (precision), recall (полнота), мера f1): 
https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit#slide=id.ga34d6fd6e8_0_730




### Домашнее задание 2. Классификация на синтетических данных (+)
0. Приведите ссылку на задание, текст задания.
1. Сгенерируйте данные. Создайте 5 или больше независимых признака, в том числе 1-2 лишних, 2 класса. [ [пример](https://colab.research.google.com/drive/1AdbtsRkX0jRVByuAKJxchYPcciTgFpqh#scrollTo=57PKhQ2Ylni1) ]
1. Проведите разведочный анализ данных.
    - 7 point summary (+),
    - диаграммы размаха, скрипичные диаграммы (violin plot),
    - матрица корреляции (+),
    - попарные диаграммы рассеяния (+),
    - столбчатую диаграмму для целевого признака, что можно сказать про баланс классов?
    - Коротко опишите данные. Сколько признаков? Какие признаки сильнее всего влияют на целевой признак? Есть ли выбросы? Какие распределения имеют признаки (нормальное, равномерное и т.п.)?
    - upd: Бонус: интерактивные диаграммы на основе plotly: гистограммы для важны?
1. Обучите модель логистической регрессии. Приведите общую формулу, пояснения для неё. (+)
1. Оцените её на отложенной выборке.
Вычислите accuracy (общую точность), точность (precision), recall (полноту), меру f1. Опишите эти показатели. (+)
1. upd: Если признаки имеют примерно одинаковую шкалу (минимумы и максимумы признаков отличаются на несколько процентов, или стандартные отклонения и средние значения признаков отличаются на несколько процентов), то опишите важность признаков, на основе коэффициентов регрессии.

Задание дополнено!


# Занятие 5. EVA. Кодирование. Pandas.
0. Повторение. Модель машинного обучения - функция потерь (ошибок) - метрики качества. Логистическая и линейная регрессия. Стандартное отклонение и математическое ожидание.
1. Выполнение консольных команд в Jupyter Notebook (в сервисе Google Colab)
1. Показатели качества модели классификации (accuracy (общая точность), точность (precision), recall (полнота), мера f1): 
https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit#slide=id.ga34d6fd6e8_0_730
2. Pandas. [Математические модели и вычислительные методы обработки экспериментальных данных](https://raw.githubusercontent.com/ivtipm/ML/main/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%20%D0%B8%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B%20%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8%20%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.pdf)]
    - Основные понятия: Колонки и данные. Создание. Загрузка из файла и загрузка по сети. Добавление колонок. Применение функции к колонкам. Выбор колонок. Заросы с фильтрами. Группировки.  
    - Пропуски
    - Дубликаты
    - Выбросы. Метод отсечения на основе стандартного отклонения.
    - Баланс классов.
3. Кодирование данных. One-hot (унитарный код); числовое кодирование (label-encoding). Масштабирование данных: нормализация и стандартизация.
4. Перекрёстная проверка (cross-validation). Рассмотрите эту тему самостоятельно. 

Пример: https://colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR?usp=sharing


### Домашнее задание 3. EVA и классификация на реальных данных
0. Приведите ссылку на задание, текст задания.
1. Используйте один из предложенных датасетов:
    - вариант 1. https://raw.githubusercontent.com/ivtipm/ML/main/datasets/churn.csv (есть на Kaggle)
    - вариант 2 (сложнее, но даёт примерно в 1.5 раза больше баллов). https://archive.ics.uci.edu/ml/datasets/adult, https://www.kaggle.com/wenruliu/adult-income-dataset?select=adult.csv
    - можно обработать оба
или предложите свой датасет, сопоставимый по количеству и качеству данных с рекомендованным. Используйте свой датасет после согласования с преподавателем.
1. Проведите разведочный анализ данных.
    - 7 point summary,
    - Пропуски, дубликаты
    - диаграммы размаха, скрипичные диаграммы (violin plot),
    - матрица корреляции,
    - попарные диаграммы рассеяния,
    - столбчатую диаграмму для целевого признака, что можно сказать про баланс классов?
    - Коротко опишите данные. Сколько признаков? Какие признаки сильнее всего влияют на целевой признак? Есть ли выбросы? Какие распределения имеют признаки (нормальное, равномерное и т.п.)?
    - Удалите лишние признаки, кодируйте нечисловые признаки, удалите выбросы, масштабируйте признаки. Поясняйте действия, описывайте зачем их производите.
    - upd: Бонус: интерактивные диаграммы на основе plotly: гистограммы для важны?
    - Опишите данные: какие данные даны? Сколько признаков и объектов? Есть ли пропуски, дубликаты, выбросы
    -  *В начале работы рекомендуется удалить все неудобные (много пропусков, нужно кодировать, есть ошибки и т.п.) признаки и построить простую модель. Записывайте как проводили обработку данных и результаты. Далее, можно более тщательно изучить и погдготовить данные, снова обучить модель и сравнить результаты с предыдущим разом.*
1. Обучите модель логистической регрессии. Приведите общую формулу, пояснения для неё.
1. Оцените её на отложенной выборке.
Вычислите accuracy (общую точность), точность (precision), recall (полноту), меру f1. Опишите эти показатели. 
1. Поэкспериментируйте с процедурой обработки данных. Удаляйте лишние столбцы, модифицируйте колонки, удаляйте выбросы и т.п. Обучайте модель после каждого эксперимента. Записывайте как каждый этап влияет на качество модели.
1. Если признаки имеют примерно одинаковую шкалу (минимумы и максимумы признаков отличаются на несколько процентов, или стандартные отклонения и средние значения признаков отличаются на несколько процентов), то опишите важность признаков, на основе коэффициентов регрессии.

Задание будет дополнено



# Занятие 6. Предварительная обработка данных. (продолжение). kNN. Масштабирование.
12 марта
1. Масштабирование данных: нормализация и стандартизация. [[пример](https://colab.research.google.com/drive/1kLfmJ4q81BNZtMs-oVX9cKJGsT3mYWmR?usp=sharing)]
Важность признаков на основе логистической и линейной регрессии. 
2. Перекрёстная проверка (cross-validation). [[слайды](https://docs.google.com/presentation/d/1mK9CfhwjQtAdJZENV3vU4nCGSkzI8_Ugkv_AavBVEaM/edit#slide=id.ga34d6fd6e8_0_709)] Рассмотрите эту тему самостоятельно. 
3. KNN. [[Теория и пример](https://colab.research.google.com/drive/1oh7-ID00MN-AoJtAm4uL-bj0sqf5ieuk?usp=sharing)]




# Занятие 7. 
18 марта
- Повторение. Алгоритм обработки данных, итеративный метод. kNN. Масштабирование. Кросс-валидация.
1. Поиск по сетке гиперпараметров. [[Теория и пример](https://colab.research.google.com/drive/1oh7-ID00MN-AoJtAm4uL-bj0sqf5ieuk?usp=sharing)]
2. SMV. [[Теория и пример](https://colab.research.google.com/drive/1oh7-ID00MN-AoJtAm4uL-bj0sqf5ieuk?usp=sharing)]
3. Решающие деревья [[colab.research.google.com/drive/1Bin_h7BPSfnxs4Pea7eibceNMkOEcKmg#scrollTo=o3dx6WQiX1m7](https://colab.research.google.com/drive/1Bin_h7BPSfnxs4Pea7eibceNMkOEcKmg#scrollTo=o3dx6WQiX1m7)]


### Домашнее задание 3.1. kNN, SVM, Решающее дерево (+)
1. Добавьте в работу 3 модели:
    - KNN
    - SVM
    - Решающее дерево

1. Добавьте в работы 1 и 2 модели:
    - KNN
    - SVM
    - Решающее дерево (как минимум в одну работу (+))

2. Подберите гиперпараметры этих моделей. Используйте класс GridSearchCV.

# Занятие 8. Ансамбли моделей. Случайный лес, бустинг и др.
https://colab.research.google.com/drive/1Bin_h7BPSfnxs4Pea7eibceNMkOEcKmg?usp=sharing#scrollTo=ORsayzp5X5Mh 


### Домашнее задание 3.2. Ансамбли (+)
1. Добавьте в работы 1, 2, 3 алгоритмы:
    - Случайный лес (как минимум в одну работу (+))
    - Градиентный бустинг



# Модуль 2. Нейросети
## Лекция 1. Многослойный персептрон
- Модель нейрона. Вход. Веса. Линейная регрессия в составе нейрона. Логиcтическая функция в составе нейрона. Функция активации (cигмода, ReLU).
- Многослойный персептрон (полносвязная нейросеть сеть). Соединения слоёв. Параметры нейросети. Построение нейросети в Keras, обучение и проверка. Особенности выходных слоёв для задачи классификации.  

- Слайды: https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit#slide=id.p
- Пример: https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing#scrollTo=hCiu6Jn2d8JE&uniqifier=1
- Короткая шпарагалка по нейросетям в фреимворке Keras: https://miro.com/app/board/uXjVNQC1rq8=/?moveToWidget=3458764571093405205&cot=14

### Домашнее задание 3.3. многослойный персептрон (+)
- Добавьте в работы 1-3 многослойный персептрон (как минимум в одну работу (+))
- Поэкспериментируйте с количеством слоёв, нейронов, функциями активации.



## Лекция 2. Персептрон. Обучение. Метод обратного распространения ошибки. Метод градиентного спуска.
- Повторение. Персептрон. 
- Обучение персептрона. Функции потерь. Метод обратного распространения ошибки для вычисления производных. 
- Метод градиентного спуска. Стохастический градиентный спуск. Learning rate (шаг обучения). Батчи. Эпохи.
- Слайды: https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit#slide=id.p
- Пример: https://colab.research.google.com/drive/1YtK4an7UAhnxTmhmQzZd6Eo3esfv6TL3?usp=sharing#scrollTo=hCiu6Jn2d8JE&uniqifier=1
- 

### Домашнее задание 3.4. Нейросети
1. Сделайте шпаргалку по нейросетям.
    - Как зависит количество нейронов на выходном слое нейросети от:
        - решаемой задачи (классификация или регрессия)?
        - количества классов, если решается задача классификации?
    - Какие функции потерь стоит использовать для классификации, а какие для регрессии? Какие функции активации стоит использовать в выходных слоях нейросети в зависимости от задачи (классификация или регрессия)?
    - Какие показатели качества стоит использовать для оценки качества решения задачи регрессии и классификации?
    - Что показывает функция потерь?
    - Как выглядит переобучение на графике функции потерь? Как выглядит переобучение на графике показателя точности предсказания?
- Как бороться с переобучением?
* Шпаргалку можно привести в ipynb файле. Используйте заголовки, схемы и формулы.
2. Добавьте в работы 1-3:
    1. отслеживание обучения нейросети по эпохам с помощью сервиса WanDB.
    2. поэкспериментируйте с количеством слоёв, нейронов, функциями активации хотя бы одной из работ. Результаты запишите в таблицу результатов обучения.
 
## Лекция 3. Отслеживание обучения. Графики обучения. WanDB. Переобучение
- Повторение. Устройство поносвязной сети. Математическая модель нейрона. Функция активации. Метод градиетного спуска. 
- Недобучение. Переобучение. https://docs.google.com/presentation/d/1YCJhQIj2BV42sDLKtxmytcYW5W39EJceYfqrYT7bKNo/edit#slide=id.p
- Отслеживание метрик моделей: [wandb.md](https://github.com/ivtipm/ML/blob/main/wandb.md)
- WandB.Графики обучения. https://colab.research.google.com/drive/1ckpgKd8eizzzuVJgHkFHLoY9bkjEmaD8?usp=sharing

## Лекция 4. Свёрточные нейросети.

0. Повторение.
1. Свёрточные нейросети. Векторные представления изображений. Свёртка. Пулинг. Архитектура AlexNet. VGG. ResNet. Inception
    - Слайды: https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit#slide=id.gc6f73a04f_0_0
2. Построение свёрточных нейросетей в keras для классификации изображений: 
2. Использование предварительно обученных нейросетей. Дообучение (fine-tuning).
- Пример https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=7mlkn05FTdFY


### Домашнее задание 4. Распознование изображений с помощью нейросети построенной на основе пакета Keras. (+-)
Выполните либо эту работу, либо следущую, по классификации текстов.

Подберите архитектуру (количетсво слоёв, количество нейронов на них, функции активации, количество эпох) в нейросети из примера чтобы достичь лушего качества, при этом не используйте слишком больше количество параметров.

*В Google Colaboratory усилились ограничения на использования видеокарт. Не запрашивайте видеокарту без необходимости.
В качестве альтернативы используйте вычислительные ресуры на Kaggle (30 часов в месяц).*


### Домашнее задание 4.1. Распознование изображений с помощью предварительно обученной нейросети (на основе фреимворка Keras)
Дообучить уже готовую модель ResNet50 (https://colab.research.google.com/drive/1kqSiP9IpPmW8dw9NxV5Sm5pMLMqfINZb#scrollTo=bE72nWTpRIeV) из примера. Получите качество лучше чем в примере.

Варианты обучения:
1. Скачать уже предварительно обученную модель ResNet50, добавить к ней полсносвязный слой (или больше слоёв). Обучить только добавленные слои.
2. Аналогично, но после дообучить всю модель целиком (разблокируйте обучение первых слоёв) с небольшим learning rate (коэффициентом шага обучения, 0.001 или меньше). Небольшой LR поможет точнее подобрать параметры, подкорректировать под новую задачу, но не испортить скаченные веса.
3. Обучить модель целиком заново.


## Лекция 5. Архитектуры  нейросетей для классификации изображений. CLIP. BERT
- Архитектуры  нейросетей для классификации изображений. AlexNet. VGG. Resnet. Inception
    - https://docs.google.com/presentation/d/1i41kqGwZqW_sSRz9Bopoq7AZf_Zuo6OaRSeCKYIH_80/edit#slide=id.g24594feff82_7_53

- CLIP - Мультимодальная (текст и изображения) нейросетевая модель. Выдаёт векторные представления текстов и изображений, которые можно сравнивать.
    - https://colab.research.google.com/drive/1IBdKzbY3sQBb7C2o03rZlLH_oYBVOpb1#scrollTo=eSd8OLqWS0oj

- BERT - нейросетевая языковая модель на основе архитектуры трансформера. Её вариант может выдавать векторные представления текста.
    - https://colab.research.google.com/drive/1Aacg8tUXXNICQ0SetvqoIPD7GXnm0Ymx#scrollTo=ac4c1025-a5e7-4684-a14f-f133b7860701


## Домашнее задание 5. Классификация текстов (+-)
Выполните либо эту работу, либо предыдущую, по распознаванию изображений.

Решите задачу классификации текстов на датасете твитов: https://github.com/cardiffnlp/tweeteval/tree/main, используйте часть датасета (`datasets\sentiment`) посвящённую анализу тональности.

Классы
```
0	negative
1	neutral
2	positive
```

Файлы датасета хранят тексты и метки классов отдельно:
- `*_labes.txt` - метки классов, по одному на строку
- `*_text.txt` - твиты, по одному на строку

Датасет уже разбит на выборку для обучения, валидации и теста: 
- `test_*.txt`
- `train_*.txt`
- `val_*.txt`

В файлах с текстом каждый твит расположен в отдельной строке. Их можно прочитать так:
```python
# чтение твитов
text = open("tweeteval-main/datasets/sentiment/train_text.txt").readlines()
# чтение класов
labels = pd.read_csv("tweeteval-main/datasets/sentiment/train_labels.txt", header=None)
# объединение в одну таблицу
Data = pd.DataFrame({'text': text, 'label':labels[0].values})
```

Можно использовать другие датасеты из репозиторий. После согласования с преподавателем можно выбрать любой другой текстовый датасет.

Создайте векторные представления текстов, с помощью нейросети основанной на архитектуре transformer, например (LABSE, Language-agnostic BERT Sentence Embedding).
Пример: https://colab.research.google.com/drive/1Aacg8tUXXNICQ0SetvqoIPD7GXnm0Ymx#scrollTo=e94a2272-af5a-4a17-a253-3fbcededbeb6

Далее используйте полученные признаки (векторные представления, Embeddings) чтобы решить задачу классификации любым из известных вам методов классификации (SVM, решающее дерево, случайные лес и др.). 

Оценить качество полученной модели на тестовой выборке.


*Бонус*:
с помощью библиотеки gradio реализуйте пользовательский интерфейс для классификации текстов, которые задаёт пользователь. 
Пример: https://github.com/ivtipm/ML/blob/main/examples/gradio.ipynb


#### Примерные варианты тем выпускных работ
1. Классификация текстов. Рекомендуемые модели и библиотеки: sklearn, TF-IDF, Sentence Transformers, BERT (для векторных представлений текстов).\
    Датасеты: 
    - части датасета tweeteval: https://github.com/cardiffnlp/tweeteval/tree/main
    - fake news: https://www.kaggle.com/datasets/stevenpeutz/misinformation-fake-news-text-dataset-79k
    - клаассификация текстов по возрастным ограничениям: https://www.kaggle.com/datasets/oldaandozerskaya/fiction-corpus-for-agebased-text-classification
    - Fake and real Russian news https://www.kaggle.com/datasets/morfifinka/fake-real-news-ru/data?select=train_bodies.csv
2. Кластеризация текстов. В данном наборе текстовых данных (документах) определить кластеры (группы схожих текстов).\ 
    Датасет: 
    - произвольный датасет их текстов, желательно не коротких (большее 300 слов)
    - научные стаьи: https://www.kaggle.com/datasets/ergkerg/russian-scientific-articles
3. Классификация изображений\
    Варианты датасетов: 
    - Классификация мусора, 12 классов, 12k объектов: https://www.kaggle.com/datasets/mostafaabla/garbage-classification/discussion/346080 
    - Классификация дорожных знаков, 40 классов, 50k объектов: https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign
    - Патологии лёгких на рентгеновских снимках, 3 класса, 33k объектов: https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/code
4. Кластеризация изображений. В данном наборе текстовых данных (документах) определить кластеры (группы схожих текстов).\
    Датасеты: можно взять собственную коллекцию фотографий (изображений)
5. Рекомендательная система для текстов\
Дан набор текстов. Из набора текстов выбрано (прочитано пользователем) несколько текстов. Найти k текстов, похожих на выбранные.\
    Датасет: 
    - произвольный набор постов, новостоей, текстов.
    - научные стаьи: https://www.kaggle.com/datasets/ergkerg/russian-scientific-articles
6. Рекомендательная система для изображений. Аналогично текстам, но для изображений.
7. Рекомендательная система для изображений, на основе текстов. Аналогично текстам, но рекомендовать изображения для текста или части текста изображения из базы данных.
8. Вопросно-ответная система на основе базы данных вопросов и ответов (рекомендация ответа на вопрос, наиболее схожий с заданным)\
Вариант темы: вопросно-ответная система на основе базы вопросов и ответов, большой языковой модели (RAG).\
Датасет:
    - произвольная база вопросов и ответов. Можно распарсить с сайтов. 
    - см. датасеты для классификации текстов
9. Можно предложить свой вариант темы или свой датасет. Обсудите его с преподавателем.

Примерный план работы
1. Изучить предоставленные данные
2. Выполнить минимально необходимую обработку данных для построения модели.
3. Построить первый вариант модели. Оценить результат.
4. Улучшить процедуру обработки данных, построить другие варианты моделей, подобрать гиперпараметры.
5. Оценить качество моделей и процедур обработки данных. Сравнить. Выбрать лучшие.
6. Опционально: разработать веб-интерфейс (например используя Gradio) или API для взаимодействия пользователя с моделью.
7. Подготовить пояснительную записку к работе. Подготовить слайды для защиты.
8. Защита работы. (ориентировочно 26 июня)


**Требования к датасетам и работам**
- Датасет изначально не должен состоять из синтетических данных.
- Выбирайте датасет в котором хотя бы несколько тысяч объектов.
- Проверяйте несколько моделей, если возможно делайте подбор гиперпараметров.
- Если в работе используются уже готовые модели и обучение не требуется, то проведите анализ разных моделей такого типа: сравните их точность (или другие показатели качества), скорость работы, объём потребляемой памяти, размер и др. параметры. 

Ещё датасеты: 
- https://habr.com/ru/articles/452392/
- https://tproger.ru/translations/the-best-datasets-for-machine-learning-and-data-science 

 


**Консультации** по выполнению работу будут проводится по расписанию каждую неделю: 
- пн, 18:00-19:00
- вт, 18:00-19:00
- чт, 19:00-20:00
